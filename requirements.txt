qdrant-client>=0.16.0
sentence-transformers>=2.7.0
colorlog>=6.8.0
numpy>=1.26.0
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.0.0
httpx>=0.25.0
# llama-cpp-python is installed separately for GPU support
# pip uninstall llama-cpp-python -y; pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121